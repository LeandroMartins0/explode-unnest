{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explode-unnest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7/Ec8aCBrKSA8mC5lP1Ve",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeandroMartins0/explode-unnest/blob/main/Explode_unnest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração de ambiente"
      ],
      "metadata": {
        "id": "eInOJppkSlAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aZQvuUb8Se_H"
      },
      "outputs": [],
      "source": [
        "# instalar as dependências\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "gu5QfBbVSqiV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tornar o pyspark \"importável\"\n",
        "\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "metadata": {
        "id": "mvDIWKgRSsUB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando pyspark e dependencias\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, StringType, ArrayType"
      ],
      "metadata": {
        "id": "xlkPK0FcSuhS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciando sessão\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkNestedFields').getOrCreate()"
      ],
      "metadata": {
        "id": "b2PfL5UxS8g6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando arquivo"
      ],
      "metadata": {
        "id": "J3fNu1erSzX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando JSON\n",
        "\n",
        "teste_df = sc.read.option(\"multiline\",\"true\").json(\"/content/test.json\")"
      ],
      "metadata": {
        "id": "znIHdN-mS2MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função Explode Unnest"
      ],
      "metadata": {
        "id": "xeh51nwiS4C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema\n",
        "\n",
        "teste_df.printSchema()"
      ],
      "metadata": {
        "id": "T4WuDd09TF5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame\n",
        "\n",
        "teste_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "UhAgz_JHTH91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "# Caso o JSON seja um array ou um map basta utilizar este código\n",
        "\n",
        "v5_struct_exploded = teste_df.withColumn(\"v5_struct_exploded\", F.explode(\"v5_struct\"))\n",
        "v5_struct_exploded.show(truncate=False)"
      ],
      "metadata": {
        "id": "UrBw7gsLTMXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "# Aqui iremos explodir novas colunas e um novo DataFrame\n",
        "\n",
        "v5_struct_exploded = v5_struct_exploded.select(\n",
        "     \"v1_string\",\n",
        "     \"v5_struct_exploded.t5\",\n",
        "     \"v5_struct_exploded.t6\",)\n",
        "\n",
        "v5_struct_exploded.show(truncate=False)"
      ],
      "metadata": {
        "id": "IKfCkUr-TX_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui temos o mesmo código porém com mais sucinto\n",
        "\n",
        "teste_df.withColumn(\"v5_struct_exploded\", F.explode(array(\"v5_struct\")))\\\n",
        "            .select(\"v1_string\",\n",
        "                    \"v5_struct_exploded.t5\",\n",
        "                    \"v5_struct_exploded.t6\",)\\\n",
        "            .show(truncate=False)"
      ],
      "metadata": {
        "id": "9P3MFFuCTbTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo para Struct dentro de Struct\n",
        "\n",
        "teste_df.withColumn(\"v7_structs_oneDriveBusiness_exploded\", F.explode(array(\"v7_structs.oneDriveBusiness\")))\\\n",
        "            .select(\"v1_string\",\n",
        "                    \"v7_structs_oneDriveBusiness_exploded.account\",\n",
        "                    \"v7_structs_oneDriveBusiness_exploded.enabled\",\n",
        "                    \"v7_structs_oneDriveBusiness_exploded.folder\",\n",
        "                    \"v7_structs_oneDriveBusiness_exploded.folderName\",)\\\n",
        "            .show(truncate=False)"
      ],
      "metadata": {
        "id": "gWSFo7zCT9Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converter struct em map"
      ],
      "metadata": {
        "id": "7uYUnqKET0VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando de struct para map\n",
        "\n",
        "from pyspark.sql.functions import col,lit,create_map\n",
        "df = teste_df.withColumn(\"v5_structMap\",create_map(\n",
        "        lit(\"t5\"),col(\"v5_struct.t5\"),\n",
        "        lit(\"t6\"),col(\"v5_struct.t6\")\n",
        "        )).drop(\"v5_struct\")\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "id": "rtwhmk-TTe7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explodindo tabela\n",
        "\n",
        "v5_structMap_exploded = df.select(\n",
        "     \"v1_string\",\n",
        "     \"v5_structMap.t5\",)\n",
        "\n",
        "v5_structMap_exploded.show(truncate=False)"
      ],
      "metadata": {
        "id": "7CC2C_n-T7fC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}